# -*- coding: utf-8 -*-
"""RandomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ff2B-cgzHrJAk5_JIcCErdRieY8Dm_ky
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, zero_one_loss
from sklearn.ensemble import RandomForestClassifier

def data_prep(df):
    df = df.astype({"id_spatial": "category", "Island": "category", "Habitat_Modification": "category", 
               "Invasive_Algae": "category", "Regime": "category"})
    return df


def load_coral_data(complete=True, CV=True, convert_to_categorical=True):
    if complete:
        df = pd.read_csv("/content/drive/My Drive/SMA project/Hawaiian_Predictors_revised.csv")
        train = pd.read_csv("/content/drive/My Drive/SMA project/Predictors_revised_train.csv")
        val = pd.read_csv("/content/drive/My Drive/SMA project/Predictors_revised_val.csv")
        test = pd.read_csv("/content/drive/My Drive/SMA project/Predictors_revised_test.csv")

    if convert_to_categorical:
        df = data_prep(df)
        train = data_prep(train)
        val = data_prep(val)
        test = data_prep(test)
        
    if CV:
        train = train.append(val)
        train = train.sample(frac=1).reset_index(drop=True)
        return df, train, test
    
    return df, train, val, test

def get_features_and_response(data):
    features =  data.iloc[:,5:-1].values
    pred_names = data.iloc[:,32].values
    response = data['Regime']
    return features, response, pred_names

def evaluate_performance(test_y, test_pred, print_vals=True):
    cnf_matrix = metrics.confusion_matrix(test_y, test_pred)
    
    class_names=['Regime1', 'Regime2', 'Regime3', 'Regime5']
    cnf_matrix = pd.DataFrame(cnf_matrix, index = class_names,
                  columns = class_names)
    
    sns.heatmap(cnf_matrix, annot=True, cmap="magma" ,fmt='g')
    plt.tight_layout()
    plt.title('Confusion matrix', y=1.1)
    plt.ylabel('Actual label')
    plt.xlabel('Predicted label')
    
    if print_vals :
        count_misclassified = (test_y != test_pred).sum()
        print('Misclassified samples: {}'.format(count_misclassified))
        accuracy = metrics.accuracy_score(test_y, test_pred)
        print('Classification Report:')
        print(metrics.classification_report(test_y, test_pred))

df, train, test = load_coral_data(complete=True, CV=True, convert_to_categorical=True)
train_X, train_y, pred_names = get_features_and_response(train)
num_trees = [1,5,10,20,25,50,75,100,125,150,200,250,300]
depth = [1, 2, 3, 4, 5,6,7,8,9,10]
hyperparameters = dict(n_estimators=num_trees, max_depth=depth)

clf = GridSearchCV(RandomForestClassifier(random_state=100), 
                  hyperparameters, cv=5, verbose=1, iid=False,
                  scoring = make_scorer(metrics.f1_score, average='micro', greater_is_better=True),
                  return_train_score=True)
best_model = clf.fit(train_X, train_y)

print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])
print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])

df, train, val, test = load_coral_data(complete=True, CV=False, convert_to_categorical=True)
val_X, val_y, pred_names = get_features_and_response(val)

rf= RandomForestClassifier(n_estimators=250, max_depth=7, random_state=100)
rf.fit(train_X, train_y)

predictions = rf.predict(val_X)

evaluate_performance(val_y, predictions)

test_X, test_y, pred_names = get_features_and_response(test)
test_pred = rf.predict(test_X)

evaluate_performance(test_y, test_pred)